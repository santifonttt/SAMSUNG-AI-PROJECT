{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fH3pZdOOJGF7"
      },
      "source": [
        "\n",
        "# LLM for outputting a user-friendly message\n",
        "\n",
        "Use the trained YAMNet+context model to produce predictions and ask a Groq LLM to turn them into clear guidance for end users.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEBRueK1Autv"
      },
      "source": [
        "\n",
        "### Loading model, data + encoder\n",
        "\n",
        "Mount Drive and load the saved classifier, label encoder, and test arrays needed for inference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiD1Jlb6AzFT",
        "outputId": "382957a8-ded5-4a92-a1ce-7d6f8c97fa09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import joblib\n",
        "import json\n",
        "\n",
        "path = 'PATH/TO/YOUR/FILES/'\n",
        "\n",
        "# Load the trained multimodal classifier\n",
        "model = load_model(path + '/yamnet_model.keras')\n",
        "\n",
        "# Load label encoder to turn indices into human-readable classes\n",
        "le = joblib.load(path + '/label_encoder.plk')\n",
        "\n",
        "# Cached test splits to reuse during inference demos\n",
        "X_audio_test = np.load(path + '/X_audio_test.npy')\n",
        "X_context_test = np.load(path + '/X_context_test.npy')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doc-install-groq"
      },
      "source": [
        "\n",
        "### Install Groq client (Colab runtime)\n",
        "\n",
        "Install the SDK in the runtime so we can call the hosted LLM.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkffZ5oYNhvZ",
        "outputId": "f4979d69-d154-4b9f-b1ff-e0ae5e288502"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting groq\n",
            "  Downloading groq-0.37.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\n",
            "Downloading groq-0.37.1-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq\n",
            "Successfully installed groq-0.37.1\n"
          ]
        }
      ],
      "source": [
        "!pip install groq  # One-time install per runtime\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doc-client-setup"
      },
      "source": [
        "\n",
        "### Configure Groq client\n",
        "\n",
        "Initialize the client with your API key (ideally set as an environment variable instead of hard-coding it).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wk6Joi0tCwIe"
      },
      "outputs": [],
      "source": [
        "from groq import Groq\n",
        "\n",
        "# Replace the string with the API key obtained from the Groq Cloud console\n",
        "client = Groq(api_key=\"API_KEY_STRING\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doc-prompt-builder"
      },
      "source": [
        "\n",
        "### Prompt builder for structured explanations\n",
        "\n",
        "Build a JSON-only prompt that keeps each predicted issue independent and outputs user-friendly advice.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "oWWulPFvft_s"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "You are an AI automotive mechanic assistant. You MUST output ONLY valid JSON with no Markdown, no backticks, and no extra text.\n",
        "\n",
        "You will receive a small set of predicted problems (top-1 or top-2). You must only return JSON objects for the problems provided.\n",
        "\n",
        "STRICT OUTPUT RULES:\n",
        "1. If only top-1 is provided, output EXACTLY one JSON object inside a JSON array.\n",
        "2. If top-2 is provided, output EXACTLY two JSON objects.\n",
        "3. NEVER output more problems than those provided.\n",
        "\n",
        "PROBLEM LABELS (allowed values):\n",
        "- \"Worn Out Brakes\"\n",
        "- \"Normal Brakes\"\n",
        "- \"Serpentine Belt\"\n",
        "- \"Car Knocking\"\n",
        "- \"Normal Engine Idle\"\n",
        "- \"Power Steering\"\n",
        "- \"Low Oil\"\n",
        "- \"Bad Ignition\"\n",
        "- \"Dead Battery\"\n",
        "- \"Normal Engine Sound\"\n",
        "- \"Normal Engine Startup\"\n",
        "\n",
        "SPECIAL RULE FOR \"NORMAL\" PROBLEMS:\n",
        "If the problem contains \"Normal\":\n",
        "- Explain that the sound/behavior is normal.\n",
        "- Provide light monitoring advice.\n",
        "\n",
        "CRITICAL GLOBAL RULE (APPLIES TO EVERY FIELD OF THE JSON):\n",
        "You MUST NOT mention, imply, or describe any cause that corresponds to ANY item from the official problem list.\n",
        "\n",
        "This restriction applies to:\n",
        "- explanation\n",
        "- possible_causes\n",
        "- recommended_actions\n",
        "- what_to_tell_the_mechanic\n",
        "- advice\n",
        "\n",
        "FORBIDDEN TERMS (DO NOT APPEAR ANYWHERE IN THE OUTPUT):\n",
        "- anything equivalent to any problem label\n",
        "\n",
        "If a concept belongs to one of the diagnostic labels above, DO NOT USE IT anywhere in the JSON.\n",
        "\n",
        "Make clear explanations.\n",
        "\n",
        "OUTPUT FORMAT FOR EACH PROBLEM:\n",
        "{\n",
        "  \"problem\": <string>,\n",
        "  \"probability\": <float>,\n",
        "  \"severity\": <\"low\" | \"moderate\" | \"high\">,\n",
        "  \"explanation\": <string WITHOUT any forbidden terms>,\n",
        "  \"possible_causes\": <list WITHOUT any forbidden terms>,\n",
        "  \"recommended_actions\": <list WITHOUT any forbidden terms>,\n",
        "  \"what_to_tell_the_mechanic\": <string WITHOUT any forbidden terms>,\n",
        "  \"advice\": <string WITHOUT any forbidden terms>\n",
        "}\n",
        "\n",
        "Your final output MUST be ONLY a valid JSON array with the above objects, nothing else.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def generate_message_json(top1_problem, top1_prob, top2_problem=None, top2_prob=None):\n",
        "    \"\"\"Create a JSON-only prompt for the LLM and parse its response.\"\"\"\n",
        "\n",
        "    # Build user message dynamically\n",
        "    if top2_problem is None:\n",
        "        user_payload = {\n",
        "            \"top_1_problem\": top1_problem,\n",
        "            \"top_1_probability\": top1_prob\n",
        "        }\n",
        "    else:\n",
        "        user_payload = {\n",
        "            \"top_1_problem\": top1_problem,\n",
        "            \"top_1_probability\": top1_prob,\n",
        "            \"top_2_problem\": top2_problem,\n",
        "            \"top_2_probability\": top2_prob\n",
        "        }\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": prompt},\n",
        "        {\"role\": \"user\", \"content\": json.dumps(user_payload)}\n",
        "    ]\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        messages=messages,\n",
        "        temperature=0.2,\n",
        "        max_tokens=500\n",
        "    )\n",
        "\n",
        "    raw_output = response.choices[0].message.content.strip()\n",
        "\n",
        "    # JSON should be clean, but just in case we remove backticks\n",
        "    cleaned_output = raw_output.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
        "\n",
        "    try:\n",
        "        decoded = json.loads(cleaned_output)\n",
        "    except json.JSONDecodeError:\n",
        "        decoded = {\"error\": \"Invalid JSON\", \"raw\": raw_output}\n",
        "\n",
        "    return decoded\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doc-full-diagnosis"
      },
      "source": [
        "\n",
        "### Run model inference and request explanation\n",
        "\n",
        "Call the trained model to get class probabilities, then format a prompt for the LLM based on confidence levels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "P_MrQXN8JXr-"
      },
      "outputs": [],
      "source": [
        "def full_diagnosis(i):\n",
        "    \"\"\"Run inference on the test split, decide whether to ask for top-1 or top-2, and fetch the JSON explanation.\"\"\"\n",
        "\n",
        "    # Prepare model inputs\n",
        "    emb = X_audio_test[i].reshape(1, -1)\n",
        "    ctx = np.array([[int(X_context_test[i])]], dtype=np.int32)\n",
        "\n",
        "    # Predictions\n",
        "    probs = model.predict([emb, ctx], verbose=0)[0]\n",
        "\n",
        "    # Top 3 ordered\n",
        "    top_idx = probs.argsort()[-3:][::-1]\n",
        "\n",
        "    top1_class = le.classes_[top_idx[0]]\n",
        "    top1_prob = float(probs[top_idx[0]])\n",
        "\n",
        "    # Case 1 → Top-1 only\n",
        "    if top1_prob >= 0.70:\n",
        "        explanation_json = generate_message_json(\n",
        "            top1_problem=top1_class,\n",
        "            top1_prob=top1_prob\n",
        "        )\n",
        "        return {\n",
        "            \"mode\": \"single\",\n",
        "            \"prediction\": top1_class,\n",
        "            \"confidence\": top1_prob,\n",
        "            \"explanation_json\": explanation_json\n",
        "        }\n",
        "\n",
        "    # Case 2 → Top-2\n",
        "    top2_class = le.classes_[top_idx[1]]\n",
        "    top2_prob = float(probs[top_idx[1]])\n",
        "\n",
        "    explanation_json = generate_message_json(\n",
        "        top1_problem=top1_class,\n",
        "        top1_prob=top1_prob,\n",
        "        top2_problem=top2_class,\n",
        "        top2_prob=top2_prob\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"mode\": \"top2\",\n",
        "        \"predictions\": [\n",
        "            (top1_class, top1_prob),\n",
        "            (top2_class, top2_prob)\n",
        "        ],\n",
        "        \"explanation_json\": explanation_json\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doc-examples"
      },
      "source": [
        "\n",
        "### Example calls\n",
        "\n",
        "Sample invocations on different test indices. Adjust the index to explore other audio clips.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_8RMJLcJeud",
        "outputId": "2a9a3767-f74c-4651-8bb7-afcd14f46f5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'mode': 'single',\n",
              " 'prediction': np.str_('car_knocking'),\n",
              " 'confidence': 0.9947447776794434,\n",
              " 'explanation_json': [{'problem': 'Car Knocking',\n",
              "   'probability': 0.9947447776794434,\n",
              "   'severity': 'high',\n",
              "   'explanation': 'The engine is producing a knocking or tapping sound, which can be caused by various factors.',\n",
              "   'possible_causes': ['Worn engine bearings',\n",
              "    'Low engine oil levels',\n",
              "    'Faulty engine mounts'],\n",
              "   'recommended_actions': ['Check engine oil levels and top off as needed',\n",
              "    'Inspect engine mounts for wear or damage',\n",
              "    'Consider a professional engine inspection'],\n",
              "   'what_to_tell_the_mechanic': \"The car is making a knocking sound, and I'm concerned it might be a serious issue.\",\n",
              "   'advice': 'Monitor the sound and report any changes to the mechanic.'}]}"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = full_diagnosis(150)\n",
        "result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt-_y-zANtK0",
        "outputId": "4a6a8409-747e-41d4-acc2-6e01ccc1664b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'mode': 'single',\n",
              " 'prediction': np.str_('dead_battery'),\n",
              " 'confidence': 0.9993599057197571,\n",
              " 'explanation_json': [{'problem': 'Dead Battery',\n",
              "   'probability': 0.9993599057197571,\n",
              "   'severity': 'high',\n",
              "   'explanation': 'The battery may be drained due to an electrical issue.',\n",
              "   'possible_causes': ['Electrical system malfunction',\n",
              "    'Faulty charging system'],\n",
              "   'recommended_actions': ['Have the battery tested and replaced if necessary',\n",
              "    'Check the electrical system for any issues'],\n",
              "   'what_to_tell_the_mechanic': \"The vehicle's battery may be dead, and it needs to be checked and possibly replaced.\",\n",
              "   'advice': 'Have the vehicle towed to a repair shop and have the battery checked as soon as possible.'}]}"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = full_diagnosis(291)\n",
        "result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doc-close"
      },
      "source": [
        "\n",
        "The `explanation_json` returned by `full_diagnosis` can be fed directly into a UI or voice assistant to give drivers friendly, actionable guidance.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
